# PDC (Position Data Center) Application

A Flask-based application for ingesting, storing, and querying trade data with REST API endpoints for blotter, positions, and alarms. Deployed on AWS ECS with automated CI/CD via GitHub Actions.

## ï¿½ SFTP Server Setup

**New to this project?** Start with the SFTP server setup:

â†’ **[ğŸ“– SFTP Quick Start Guide](./QUICKSTART.md)** - 5 minutes to a working SFTP server

â†’ **[âœ… SFTP Setup Checklist](./SETUP_CHECKLIST.md)** - Interactive step-by-step guide

â†’ **[ğŸ“‘ Complete SFTP Documentation](./README_SFTP_SETUP.md)** - Everything you need to know

## ï¿½ğŸ“‹ Table of Contents

- [SFTP Setup](#sftp-server-setup) â† **Start here if new!**
- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Local Development](#local-development)
- [AWS Deployment](#aws-deployment)
- [API Endpoints](#api-endpoints)
- [Configuration](#configuration)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)

**ğŸ“š Complete documentation files:**
- `QUICKSTART.md` - 3-step quick setup
- `SETUP_CHECKLIST.md` - Interactive checklist
- `SETUP_FLOWCHART.md` - Visual diagrams
- `README_SFTP_SETUP.md` - Comprehensive guide
- `DOCUMENTATION_INDEX.md` - Index of all documentation

## âœ¨ Features

- **SFTP File Ingestion**: Automated ingestion of trade data files via SFTP
- **REST API**: Query blotter, positions, and alarms with API key authentication
- **Scheduled Tasks**: EventBridge-triggered ECS tasks for periodic data ingestion
- **Health Monitoring**: Health check and metrics endpoints for observability
- **AWS Infrastructure**: Fully automated deployment with Terraform
- **CI/CD Pipeline**: GitHub Actions workflow for automated deployments

## ğŸ—ï¸ Architecture

### AWS Infrastructure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application    â”‚
â”‚  Load Balancer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  ECS    â”‚
    â”‚ Service â”‚
    â”‚ (Fargate)â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RDS    â”‚      â”‚  EventBridge â”‚
    â”‚PostgreSQLâ”‚      â”‚  (Scheduled) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                           â”‚
                      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                      â”‚  ECS    â”‚
                      â”‚  Task   â”‚
                      â”‚(Ingestion)â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

- **VPC**: Isolated network with public subnets
- **Application Load Balancer (ALB)**: Routes traffic to ECS tasks
- **ECS Fargate**: Container orchestration for the Flask application
- **RDS PostgreSQL**: Managed database for trade data
- **ECR**: Docker image registry
- **EventBridge**: Scheduled ingestion tasks
- **CloudWatch**: Logging and monitoring

## ğŸ“¦ Prerequisites

### Local Development

- Python 3.11+
- SQLite (included with Python) or PostgreSQL (for production-like setup)
- Git
- Virtual environment (venv)
- Docker (optional, for SFTP testing)

### AWS Deployment

- AWS Account with appropriate IAM permissions
- Terraform >= 1.0
- Docker (for building images)
- AWS CLI configured
- GitHub repository with Actions enabled

## ğŸš€ Local Development

### 1. Clone Repository

```bash
git clone <repository-url>
cd vest
```

### 2. Create Virtual Environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

Create a `.env` file in the root directory:

```env
# API URL for smoke tests
API_URL="http://127.0.0.1:5001"

# Database - Use SQLite for easy local setup
DATABASE_URL=sqlite:///pdc.db

# For PostgreSQL (alternative):
# DATABASE_URL=postgresql://postgres:postgres@localhost:5432/pdc_db

# API Security
API_KEY=dev-api-key
SECRET_KEY=dev-secret-key-change-in-production

# SFTP Configuration (optional for local dev)
# Note: SFTP_HOST_PORT is for Docker port mapping
SFTP_HOST='127.0.0.1'
SFTP_HOST_PORT=3022    # host port defined in docker-compose
SFTP_PORT=3022         # the port the Python app connects to
SFTP_USERNAME=sftp_user
SFTP_KEY_PATH=~/.ssh/id_pdc
SFTP_REMOTE_PATH=/uploads
SFTP_PROCESSED_PATH=/processed

# Alerting (optional for now)
ALERT_SERVICE_URL=http://localhost:5002/alerts
ALERT_API_KEY=alert-api-key
```

**Note**: The application will automatically use SQLite (`pdc.db`) if `DATABASE_URL` is set to `sqlite:///pdc.db`. For production-like testing, you can use PostgreSQL instead.

### 5. Set Up Database

**For SQLite (default)**: No setup needed! The database file will be created automatically.

**For PostgreSQL (optional)**:
```bash
# Create database
createdb pdc_db

# Or using psql
psql -U postgres -c "CREATE DATABASE pdc_db;"
```

### 6. Initialize Database Schema

```bash
python -c "from app import create_app, db; from app.config import Config; app = create_app(Config); app.app_context().push(); db.create_all()"
```

### 7. Run Application

```bash
python run.py
```

The application will be available at `http://127.0.0.1:5001`

### 8. Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_routes.py
```

## â˜ï¸ AWS Deployment

### Prerequisites

1. **AWS IAM Permissions**: Your AWS account must have permissions to create:
   - VPC, Subnets, Security Groups
   - ECS Clusters, Services, Task Definitions
   - RDS Instances
   - ALB, Target Groups, Listeners
   - ECR Repositories
   - IAM Roles and Policies (under `/interview/` path)
   - EventBridge Rules

2. **Terraform Backend**: S3 bucket for Terraform state
   - Bucket: `pdc-terraform-state`
   - Region: `us-east-2`

3. **GitHub Secrets**: Configure in your repository settings:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`

### Terraform Configuration

1. **Copy example variables file**:

```bash
cd terraform
cp terraform.tfvars.example terraform.tfvars
```

2. **Edit `terraform.tfvars`**:

```hcl
aws_region = "us-east-2"
db_instance_class = "db.t3.micro"
db_username = "postgres"
db_password = "your-secure-password"
api_key = "your-api-key"
sftp_host = "your-sftp-host"
sftp_username = "your-sftp-user"
```

3. **Initialize Terraform**:

```bash
terraform init
```

4. **Plan Deployment**:

```bash
terraform plan -out=tfplan
```

5. **Apply Changes**:

```bash
terraform apply tfplan
```

### Automated CI/CD Deployment

The project includes a GitHub Actions workflow that automatically deploys on push to `main`:

1. **Push to GitHub**:
```bash
git add .
git commit -m "Your changes"
git push origin main
```

2. **Monitor Deployment**:
   - Go to GitHub â†’ Actions tab
   - Watch the "Deploy to AWS" workflow

3. **Workflow Steps**:
   - Configure AWS credentials
   - Set up Terraform
   - Initialize Terraform
   - Plan infrastructure changes
   - Build Docker image
   - Push to ECR
   - Apply Terraform changes
   - Update ECS service
   - Run smoke tests

### Get Deployment Information

```bash
# Get ALB DNS name
terraform output alb_dns_name

# Get database endpoint
terraform output database_endpoint

# Get ECR repository URL
terraform output ecr_repository_url
```

## ğŸ”Œ API Endpoints

### Health & Metrics

- **GET `/health`**: Health check endpoint
  ```bash
  curl http://localhost:5001/health
  ```

- **GET `/metrics`**: Basic metrics
  ```bash
  curl http://localhost:5001/metrics
  ```

### API Endpoints (Require API Key)

All API endpoints require authentication via `X-API-Key` header or `api_key` query parameter.

- **GET `/api/blotter`**: Get trade blotter
  ```bash
  curl -H "X-API-Key: your-api-key" \
    "http://localhost:5001/api/blotter?date=2025-01-15"
  ```

- **GET `/api/positions`**: Get positions
  ```bash
  curl -H "X-API-Key: your-api-key" \
    "http://localhost:5001/api/positions?date=2025-01-15"
  ```

- **GET `/api/alarms`**: Get alarms
  ```bash
  curl -H "X-API-Key: your-api-key" \
    "http://localhost:5001/api/alarms?date=2025-01-15"
  ```

### Query Parameters

- `date`: Filter by trade date (YYYY-MM-DD format)
- `account_id`: Filter by account ID
- `ticker`: Filter by ticker symbol
- `api_key`: API key (alternative to header)

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `API_URL` | API URL for smoke tests | `http://127.0.0.1:5001` |
| `DATABASE_URL` | Database connection string (SQLite or PostgreSQL) | `sqlite:///pdc.db` |
| `API_KEY` | API authentication key | `dev-api-key-change-in-production` |
| `SECRET_KEY` | Flask secret key | `dev-secret-key-change-in-production` |
| `SFTP_HOST` | SFTP server hostname | `127.0.0.1` |
| `SFTP_HOST_PORT` | SFTP host port (for Docker port mapping) | `3022` |
| `SFTP_PORT` | SFTP server port (the port app connects to) | `3022` |
| `SFTP_USERNAME` | SFTP username | `sftp_user` |
| `SFTP_KEY_PATH` | Path to SSH private key | `~/.ssh/id_pdc` |
| `SFTP_REMOTE_PATH` | Remote SFTP path | `/uploads` |
| `SFTP_PROCESSED_PATH` | Processed files path | `/processed` |
| `ALERT_SERVICE_URL` | Alert service endpoint | `http://localhost:5002/alerts` |
| `ALERT_API_KEY` | Alert service API key | `alert-api-key` |
| `PORT` | Application port (local dev) | `5001` |
| `HOST` | Application host (local dev) | `127.0.0.1` |

### Terraform Variables

See `terraform/variables.tf` for all available variables.

## ğŸ§ª Testing

### Unit Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test
pytest tests/test_routes.py -v
```

### Smoke Tests

Test deployed application:

```bash
# Local
export API_URL="http://localhost:5001"
python scripts/smoketest.py

# AWS (after deployment)
export API_URL="http://$(terraform output -raw alb_dns_name)"
python scripts/smoketest.py
```

### API Testing

```bash
# Test API endpoints
python scripts/test_api.py
```

## ğŸ”§ Troubleshooting

### Local Development Issues

**Database Connection Error**:
- **For SQLite**: Check file permissions in the project directory
- **For PostgreSQL**: 
  - Verify PostgreSQL is running: `pg_isready`
  - Check `DATABASE_URL` in `.env`
  - Ensure database exists: `psql -l | grep pdc_db`

**Port Already in Use**:
- Change `PORT` in `.env` to a different port
- Or kill the process using the port

**Import Errors**:
- Ensure virtual environment is activated
- Reinstall dependencies: `pip install -r requirements.txt`

### AWS Deployment Issues

**Terraform IAM Errors**:
- Verify IAM permissions allow creating roles under `/interview/` path
- Check that permissions boundary is set correctly
- Ensure roles don't already exist at root path

**ECS Tasks Not Starting**:
- Check CloudWatch logs: `/ecs/pdc-app`
- Verify security group allows port 5000 from ALB
- Check task definition health check configuration
- Verify `DATABASE_URL` is correct (no duplicate port)

**Health Checks Failing**:
- Ensure `curl` is installed in Docker image
- Check health check timeout and start period settings
- Verify application is listening on port 5000
- Check security group rules

**Database Connection Issues**:
- Verify RDS security group allows connections from ECS security group
- Check `DATABASE_URL` format (should be `postgresql://user:pass@host/db`, not `host:5432:5432`)
- Verify database credentials in Terraform variables

**ALB 503 Errors**:
- Check target group health: AWS Console â†’ EC2 â†’ Target Groups
- Verify ECS tasks are running and healthy
- Check security group allows ALB â†’ ECS communication on port 5000

### Common Fixes

1. **Rebuild Docker Image**:
   ```bash
   docker build -t pdc-app .
   ```

2. **Check ECS Task Logs**:
   ```bash
   aws logs tail /ecs/pdc-app --follow
   ```

3. **Verify Terraform State**:
   ```bash
   terraform state list
   ```

4. **Force ECS Service Update**:
   ```bash
   aws ecs update-service --cluster pdc-cluster --service pdc-app-service --force-new-deployment
   ```

## ğŸ“ Project Structure

```
vest/
â”œâ”€â”€ app/                    # Flask application
â”‚   â”œâ”€â”€ __init__.py        # App factory
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”œâ”€â”€ models.py          # Database models
â”‚   â”œâ”€â”€ routes.py          # API routes
â”‚   â”œâ”€â”€ middleware.py      # Request middleware
â”‚   â””â”€â”€ services/          # Business logic
â”‚       â”œâ”€â”€ sftp_service.py
â”‚       â”œâ”€â”€ file_ingestion.py
â”‚       â”œâ”€â”€ ingestion_worker.py
â”‚       â””â”€â”€ alerting_service.py
â”œâ”€â”€ terraform/             # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf           # Main infrastructure
â”‚   â”œâ”€â”€ ecs.tf            # ECS configuration
â”‚   â”œâ”€â”€ scheduled_task.tf # EventBridge tasks
â”‚   â”œâ”€â”€ variables.tf      # Variable definitions
â”‚   â””â”€â”€ outputs.tf        # Output values
â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â”œâ”€â”€ smoketest.py      # Smoke tests
â”‚   â”œâ”€â”€ test_api.py       # API tests
â”‚   â””â”€â”€ ingest_files.py   # Data ingestion
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml     # CI/CD pipeline
â”œâ”€â”€ Dockerfile            # Docker image definition
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ run.py               # Application entry point
```


